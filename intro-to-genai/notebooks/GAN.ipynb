{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "1. collected and preprocessed the data, Trained the model of generator, discriminator. evaluated with the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "from pathlib import Path  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "IMG_SIZE = 64\n",
    "BATCH_SIZE = 32\n",
    "LATENT_DIM = 100\n",
    "EPOCHS = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess dataset\n",
    "def load_images(dataset_path):\n",
    "    images = []\n",
    "    for file in glob.glob(os.path.join(dataset_path, \"*.jpg\")):\n",
    "        img = Image.open(file).convert(\"RGB\")\n",
    "        img = img.resize((IMG_SIZE, IMG_SIZE))\n",
    "        img = np.array(img) / 255.0  # Normalize to [0,1]\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "current_directory = Path().resolve()\n",
    "data_directory = current_directory.parent / 'data'\n",
    "dataset_path = data_directory / \"GAN_data\"\n",
    "images = load_images(dataset_path)\n",
    "dataset = tf.data.Dataset.from_tensor_slices(images).shuffle(1000).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator model\n",
    "def build_generator():\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(8 * 8 * 256, use_bias=False, input_shape=(LATENT_DIM,)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(),\n",
    "        layers.Reshape((8, 8, 256)),\n",
    "        layers.Conv2DTranspose(128, (5,5), strides=(2,2), padding='same', use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(),\n",
    "        layers.Conv2DTranspose(64, (5,5), strides=(2,2), padding='same', use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(),\n",
    "        layers.Conv2DTranspose(3, (5,5), strides=(2,2), padding='same', activation='tanh')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Discriminator model\n",
    "def build_discriminator():\n",
    "    model = keras.Sequential([\n",
    "        layers.Conv2D(64, (5,5), strides=(2,2), padding='same', input_shape=[IMG_SIZE, IMG_SIZE, 3]),\n",
    "        layers.LeakyReLU(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Conv2D(128, (5,5), strides=(2,2), padding='same'),\n",
    "        layers.LeakyReLU(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "generator = build_generator()\n",
    "discriminator = build_discriminator()\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(1e-4), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gan(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    gan_input = keras.Input(shape=(LATENT_DIM,))\n",
    "    generated_image = generator(gan_input)\n",
    "    gan_output = discriminator(generated_image)\n",
    "    gan = keras.Model(gan_input, gan_output)\n",
    "    gan.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(1e-4))\n",
    "    return gan\n",
    "\n",
    "gan = build_gan(generator, discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train(dataset, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        for batch in dataset:\n",
    "            noise = np.random.normal(0, 1, (BATCH_SIZE, LATENT_DIM))\n",
    "            generated_images = generator.predict(noise)\n",
    "            real_labels = np.ones((BATCH_SIZE, 1))\n",
    "            fake_labels = np.zeros((BATCH_SIZE, 1))\n",
    "            \n",
    "            # Train discriminator\n",
    "            d_loss_real = discriminator.train_on_batch(batch, real_labels)\n",
    "            d_loss_fake = discriminator.train_on_batch(generated_images, fake_labels)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            \n",
    "            # Train generator\n",
    "            noise = np.random.normal(0, 1, (BATCH_SIZE, LATENT_DIM))\n",
    "            misleading_labels = np.ones((BATCH_SIZE, 1))\n",
    "            g_loss = gan.train_on_batch(noise, misleading_labels)\n",
    "            \n",
    "        if epoch % 1000 == 0:\n",
    "            print(f\"Epoch {epoch}/{epochs}, D Loss: {d_loss[0]}, G Loss: {g_loss}\")\n",
    "            generate_and_save_images(generator, epoch)\n",
    "\n",
    "def generate_and_save_images(model, epoch):\n",
    "    noise = np.random.normal(0, 1, (16, LATENT_DIM))\n",
    "    generated_images = model.predict(noise)\n",
    "    generated_images = (generated_images + 1) / 2.0  # Rescale to [0,1]\n",
    "    fig, axs = plt.subplots(4, 4, figsize=(6,6))\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            axs[i, j].imshow(generated_images[i * 4 + j])\n",
    "            axs[i, j].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "train(dataset, EPOCHS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cognizant_projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
