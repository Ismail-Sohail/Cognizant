{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Overview\n",
    "1. Took the summary of AI\n",
    "2. Preprocessed, Tokenization, padding, Split the data, and train the baseline LSTM model\n",
    "3. Implelemted the hyperparameter tuning with the Random search and Bayesian Optimization\n",
    "4. Overfitting was tackled by implementing dropouts, batch normalization and so on\n",
    "5. Evalauted the model with the metrics Perplexity, Blue score and Rouge Score.\n",
    "\n",
    "Final Outcome: Since data was less and the model was not able to generalise more.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "7nxZCJVT5M2Q",
    "outputId": "e1d2d4fc-834e-4cc9-80d4-216ad52b6e06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge-score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge-score) (3.9.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.17.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (8.1.8)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (4.67.1)\n",
      "Building wheels for collected packages: rouge-score\n",
      "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=18cb2197625667b407de20254978a8872f7e1fcd6f28c27a2d688533a44c9803\n",
      "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
      "Successfully built rouge-score\n",
      "Installing collected packages: rouge-score\n",
      "Successfully installed rouge-score-0.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "e_ldiJgU5KHg",
    "outputId": "d38fb29c-1e5c-4fd7-ebbc-18c7eb42466d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-tuner\n",
      "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (3.8.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (24.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (2.32.3)\n",
      "Collecting kt-legacy (from keras-tuner)\n",
      "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.4.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.26.4)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (13.9.4)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.0.8)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (3.12.1)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.14.1)\n",
      "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2025.1.31)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras->keras-tuner) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
      "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
      "Installing collected packages: kt-legacy, keras-tuner\n",
      "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-tuner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Skwyv7Dw47rl"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from rouge_score import rouge_scorer\n",
    "import keras_tuner as kt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B66luF5YtuDK",
    "outputId": "ca463834-71df-4177-9afa-46d51fd0b49d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artificial intelligence transforming the future introduction artificial intelligence ai is one of the most revolutionary advancement of the 21st century it ha permeated every aspect of human life from healthcare and finance to transportation and entertainment ai refers to the simulation of human intelligence in machine enabling them to learn reason and perform task that traditionally required human cognition a ai continues to evolve it raise critical question about it potential ethical implication and societal impact the evolution of ai the concept of ai date back to ancient mythology where automated being were imagined however ai a a scientific discipline emerged in the mid20th century alan turing a pioneer in computing proposed the idea of machine that could mimic human intelligence in 1956 the dartmouth conference officially introduced ai a a field of study ai development can be categorized into three wave 1 symbolic ai 1950s1980s early ai relied on rulebased system and logic programming however these system struggled with complex task requiring intuition or vast amount of data 2 machine learning 1990s2010s the advent of neural network and statistical model enabled machine to learn from data rather than relying solely on predefined rule 3 deep learning and ai today 2010spresent advance in computing power and data availability have led to deep learning model that surpass human performance in specific task such a image recognition and natural language processing type of artificial intelligence ai is broadly categorized into three type 1 narrow ai weak ai this type of ai is designed for specific task such a facial recognition recommendation system and autonomous vehicle example include siri google assistant and netflixs recommendation engine 2 general ai strong ai general ai possesses humanlike cognitive ability enabling it to understand learn and apply knowledge across different domain this level of ai remains theoretical 3 super ai a hypothetical ai surpassing human intelligence potentially possessing selfawareness reasoning ability and superior problemsolving skill this concept is often discussed in science fiction and philosophical debate application of ai ai ha penetrated various industry revolutionizing traditional process and enhancing efficiency some key application include 1 healthcare aipowered system assist in diagnosing disease predicting patient outcome and personalizing treatment plan for example ibm watson can analyze medical literature and provide insight to doctor ai is also instrumental in drug discovery and roboticassisted surgery 2 finance in the financial sector aidriven algorithm detect fraudulent transaction automate trading strategy and provide personalized financial advice ai chatbots enhance customer service by resolving query in real time 3 transportation ai is the backbone of autonomous vehicle optimizing traffic management and enhancing safety company like tesla and waymo are pioneering selfdriving car technology 4 retail and ecommerce ai personalizes customer experience by analyzing purchase behavior and recommending product chatbots and virtual assistant streamline customer service while aidriven supply chain management improves logistics 5 entertainment and medium streaming service like netflix and spotify use ai to recommend content based on user preference ai also generates music script and digital art transforming the creative industry ethical and social implication while ai brings numerous benefit it also raise ethical concern 1 job displacement automation threatens traditional job particularly in industry like manufacturing and customer service however it also creates new opportunity in ai development data science and cybersecurity 2 bias and fairness ai model can inherit bias from training data leading to unfair outcome in hiring lending and law enforcement ensuring transparency and fairness in ai decisionmaking is crucial 3 privacy concern aidriven surveillance and data collection pose privacy risk government and organization must establish robust regulation to protect user data 4 autonomous weapon the development of aipowered military system raise concern about ethical warfare autonomous weapon may operate without human intervention leading to unintended consequence the future of ai the future of ai hold immense potential researcher are working on enhancing ai interpretability ensuring ethical ai practice and developing humanai collaboration model some emerging trend include 1 explainable ai xai effort are being made to create transparent ai system that provide reasoning behind their decision 2 ai in space exploration ai is being used to analyze cosmic data predict astronomical event and assist in interplanetary mission 3 ai for climate change ai model predict climate pattern optimize energy consumption and enhance sustainability effort 4 ai and human enhancement braincomputer interface and aidriven prosthetics are revolutionizing healthcare and augmenting human capability conclusion artificial intelligence is transforming the world in unprecedented way while it present remarkable opportunity ethical challenge must be addressed to ensure responsible ai deployment a ai continues to evolve society must strike a balance between innovation and ethical consideration fostering a future where ai benefit humanity without compromising fundamental value\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Sample text corpus\n",
    "text = \"\"\"**Artificial Intelligence: Transforming the Future**\n",
    "\n",
    "### Introduction\n",
    "\n",
    "Artificial Intelligence (AI) is one of the most revolutionary advancements of the 21st century. It has permeated every aspect of human life, from healthcare and finance to transportation and entertainment. AI refers to the simulation of human intelligence in machines, enabling them to learn, reason, and perform tasks that traditionally required human cognition. As AI continues to evolve, it raises critical questions about its potential, ethical implications, and societal impact.\n",
    "\n",
    "### The Evolution of AI\n",
    "\n",
    "The concept of AI dates back to ancient mythology, where automated beings were imagined. However, AI as a scientific discipline emerged in the mid-20th century. Alan Turing, a pioneer in computing, proposed the idea of machines that could mimic human intelligence. In 1956, the Dartmouth Conference officially introduced AI as a field of study.\n",
    "\n",
    "AI development can be categorized into three waves:\n",
    "\n",
    "1. **Symbolic AI (1950s–1980s)**: Early AI relied on rule-based systems and logic programming. However, these systems struggled with complex tasks requiring intuition or vast amounts of data.\n",
    "2. **Machine Learning (1990s–2010s)**: The advent of neural networks and statistical models enabled machines to learn from data rather than relying solely on pre-defined rules.\n",
    "3. **Deep Learning and AI Today (2010s–present)**: Advances in computing power and data availability have led to deep learning models that surpass human performance in specific tasks, such as image recognition and natural language processing.\n",
    "\n",
    "### Types of Artificial Intelligence\n",
    "\n",
    "AI is broadly categorized into three types:\n",
    "\n",
    "1. **Narrow AI (Weak AI)**: This type of AI is designed for specific tasks, such as facial recognition, recommendation systems, and autonomous vehicles. Examples include Siri, Google Assistant, and Netflix’s recommendation engine.\n",
    "2. **General AI (Strong AI)**: General AI possesses human-like cognitive abilities, enabling it to understand, learn, and apply knowledge across different domains. This level of AI remains theoretical.\n",
    "3. **Super AI**: A hypothetical AI surpassing human intelligence, potentially possessing self-awareness, reasoning abilities, and superior problem-solving skills. This concept is often discussed in science fiction and philosophical debates.\n",
    "\n",
    "### Applications of AI\n",
    "\n",
    "AI has penetrated various industries, revolutionizing traditional processes and enhancing efficiency. Some key applications include:\n",
    "\n",
    "#### 1. **Healthcare**\n",
    "AI-powered systems assist in diagnosing diseases, predicting patient outcomes, and personalizing treatment plans. For example, IBM Watson can analyze medical literature and provide insights to doctors. AI is also instrumental in drug discovery and robotic-assisted surgeries.\n",
    "\n",
    "#### 2. **Finance**\n",
    "In the financial sector, AI-driven algorithms detect fraudulent transactions, automate trading strategies, and provide personalized financial advice. AI chatbots enhance customer service by resolving queries in real time.\n",
    "\n",
    "#### 3. **Transportation**\n",
    "AI is the backbone of autonomous vehicles, optimizing traffic management and enhancing safety. Companies like Tesla and Waymo are pioneering self-driving car technology.\n",
    "\n",
    "#### 4. **Retail and E-commerce**\n",
    "AI personalizes customer experiences by analyzing purchase behavior and recommending products. Chatbots and virtual assistants streamline customer service, while AI-driven supply chain management improves logistics.\n",
    "\n",
    "#### 5. **Entertainment and Media**\n",
    "Streaming services like Netflix and Spotify use AI to recommend content based on user preferences. AI also generates music, scripts, and digital art, transforming the creative industry.\n",
    "\n",
    "### Ethical and Social Implications\n",
    "\n",
    "While AI brings numerous benefits, it also raises ethical concerns:\n",
    "\n",
    "#### 1. **Job Displacement**\n",
    "Automation threatens traditional jobs, particularly in industries like manufacturing and customer service. However, it also creates new opportunities in AI development, data science, and cybersecurity.\n",
    "\n",
    "#### 2. **Bias and Fairness**\n",
    "AI models can inherit biases from training data, leading to unfair outcomes in hiring, lending, and law enforcement. Ensuring transparency and fairness in AI decision-making is crucial.\n",
    "\n",
    "#### 3. **Privacy Concerns**\n",
    "AI-driven surveillance and data collection pose privacy risks. Governments and organizations must establish robust regulations to protect user data.\n",
    "\n",
    "#### 4. **Autonomous Weapons**\n",
    "The development of AI-powered military systems raises concerns about ethical warfare. Autonomous weapons may operate without human intervention, leading to unintended consequences.\n",
    "\n",
    "### The Future of AI\n",
    "\n",
    "The future of AI holds immense potential. Researchers are working on enhancing AI’s interpretability, ensuring ethical AI practices, and developing human-AI collaboration models. Some emerging trends include:\n",
    "\n",
    "1. **Explainable AI (XAI)**: Efforts are being made to create transparent AI systems that provide reasoning behind their decisions.\n",
    "2. **AI in Space Exploration**: AI is being used to analyze cosmic data, predict astronomical events, and assist in interplanetary missions.\n",
    "3. **AI for Climate Change**: AI models predict climate patterns, optimize energy consumption, and enhance sustainability efforts.\n",
    "4. **AI and Human Enhancement**: Brain-computer interfaces and AI-driven prosthetics are revolutionizing healthcare and augmenting human capabilities.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Artificial Intelligence is transforming the world in unprecedented ways. While it presents remarkable opportunities, ethical challenges must be addressed to ensure responsible AI deployment. As AI continues to evolve, society must strike a balance between innovation and ethical considerations, fostering a future where AI benefits humanity without compromising fundamental values.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Download nltk resources\n",
    "#nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'@\\w+|#\\w+|\\*+', '', text)  # Remove @, #, *\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)  # Remove special characters\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
    "    words = text.split()\n",
    "\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Apply preprocessing\n",
    "clean_text = preprocess_text(text)\n",
    "\n",
    "\n",
    "print(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hz6wDYNstx8Z",
    "outputId": "a23248d9-4bb7-426b-8e35-3e68f7988a52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from hyperparam_tuning/text_gen_lstm/tuner0.json\n",
      "Epoch 1/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 117ms/step - accuracy: 0.0393 - loss: 5.9893 - val_accuracy: 0.0452 - val_loss: 5.8096\n",
      "Epoch 2/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.0675 - loss: 5.5781 - val_accuracy: 0.0452 - val_loss: 6.0086\n",
      "Epoch 3/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 97ms/step - accuracy: 0.0665 - loss: 5.4523 - val_accuracy: 0.0452 - val_loss: 6.3045\n",
      "Epoch 4/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 99ms/step - accuracy: 0.0665 - loss: 5.4271 - val_accuracy: 0.0452 - val_loss: 6.4766\n",
      "Epoch 5/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.0610 - loss: 5.4293 - val_accuracy: 0.0452 - val_loss: 6.6061\n",
      "Epoch 6/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - accuracy: 0.0743 - loss: 5.3805 - val_accuracy: 0.0452 - val_loss: 6.6954\n",
      "Epoch 7/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.0741 - loss: 5.3828 - val_accuracy: 0.0452 - val_loss: 6.7348\n",
      "Epoch 8/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.0598 - loss: 5.4150 - val_accuracy: 0.0452 - val_loss: 6.8601\n",
      "Epoch 9/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.0705 - loss: 5.3564 - val_accuracy: 0.0452 - val_loss: 6.8315\n",
      "Epoch 10/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.0501 - loss: 5.3164 - val_accuracy: 0.0387 - val_loss: 6.9541\n",
      "Epoch 11/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.0538 - loss: 5.2267 - val_accuracy: 0.0516 - val_loss: 6.7780\n",
      "Epoch 12/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - accuracy: 0.0742 - loss: 5.0219 - val_accuracy: 0.0387 - val_loss: 7.0767\n",
      "Epoch 13/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.0777 - loss: 4.9317 - val_accuracy: 0.0645 - val_loss: 7.5606\n",
      "Epoch 14/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.0567 - loss: 4.9632 - val_accuracy: 0.0581 - val_loss: 7.7621\n",
      "Epoch 15/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - accuracy: 0.0950 - loss: 4.7090 - val_accuracy: 0.0452 - val_loss: 8.1968\n",
      "Epoch 16/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.0779 - loss: 4.6063 - val_accuracy: 0.0323 - val_loss: 8.4683\n",
      "Epoch 17/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - accuracy: 0.0986 - loss: 4.3622 - val_accuracy: 0.0323 - val_loss: 9.1375\n",
      "Epoch 18/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - accuracy: 0.1170 - loss: 4.1403 - val_accuracy: 0.0323 - val_loss: 10.0163\n",
      "Epoch 19/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - accuracy: 0.1465 - loss: 3.8367 - val_accuracy: 0.0194 - val_loss: 10.6620\n",
      "Epoch 20/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 99ms/step - accuracy: 0.1892 - loss: 3.5505 - val_accuracy: 0.0129 - val_loss: 11.6953\n",
      "Epoch 21/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - accuracy: 0.1861 - loss: 3.3518 - val_accuracy: 0.0194 - val_loss: 12.5510\n",
      "Epoch 22/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.2232 - loss: 3.0426 - val_accuracy: 0.0258 - val_loss: 13.2682\n",
      "Epoch 23/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.2599 - loss: 2.8088 - val_accuracy: 0.0387 - val_loss: 13.9433\n",
      "Epoch 24/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.3173 - loss: 2.6716 - val_accuracy: 0.0323 - val_loss: 14.5789\n",
      "Epoch 25/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - accuracy: 0.3607 - loss: 2.3993 - val_accuracy: 0.0452 - val_loss: 15.4056\n",
      "Epoch 26/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.4383 - loss: 2.2091 - val_accuracy: 0.0323 - val_loss: 15.6599\n",
      "Epoch 27/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - accuracy: 0.4921 - loss: 2.0009 - val_accuracy: 0.0387 - val_loss: 16.3706\n",
      "Epoch 28/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - accuracy: 0.5737 - loss: 1.7985 - val_accuracy: 0.0452 - val_loss: 16.8244\n",
      "Epoch 29/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.5932 - loss: 1.6931 - val_accuracy: 0.0323 - val_loss: 17.6646\n",
      "Epoch 30/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.6537 - loss: 1.4590 - val_accuracy: 0.0452 - val_loss: 17.8777\n",
      "Epoch 31/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - accuracy: 0.7125 - loss: 1.2751 - val_accuracy: 0.0323 - val_loss: 18.7525\n",
      "Epoch 32/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - accuracy: 0.7942 - loss: 1.0473 - val_accuracy: 0.0452 - val_loss: 19.1414\n",
      "Epoch 33/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.8519 - loss: 0.8930 - val_accuracy: 0.0452 - val_loss: 19.5683\n",
      "Epoch 34/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - accuracy: 0.8848 - loss: 0.7672 - val_accuracy: 0.0323 - val_loss: 20.1245\n",
      "Epoch 35/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.8899 - loss: 0.6845 - val_accuracy: 0.0516 - val_loss: 20.4040\n",
      "Epoch 36/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - accuracy: 0.9190 - loss: 0.5681 - val_accuracy: 0.0387 - val_loss: 21.2814\n",
      "Epoch 37/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.9325 - loss: 0.5184 - val_accuracy: 0.0516 - val_loss: 21.2468\n",
      "Epoch 38/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - accuracy: 0.9445 - loss: 0.4298 - val_accuracy: 0.0323 - val_loss: 21.6284\n",
      "Epoch 39/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - accuracy: 0.9626 - loss: 0.3951 - val_accuracy: 0.0258 - val_loss: 22.0013\n",
      "Epoch 40/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - accuracy: 0.9796 - loss: 0.2876 - val_accuracy: 0.0387 - val_loss: 22.5477\n",
      "Epoch 41/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.9918 - loss: 0.2440 - val_accuracy: 0.0452 - val_loss: 22.7423\n",
      "Epoch 42/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - accuracy: 0.9962 - loss: 0.1909 - val_accuracy: 0.0387 - val_loss: 23.0640\n",
      "Epoch 43/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - accuracy: 0.9978 - loss: 0.1552 - val_accuracy: 0.0452 - val_loss: 23.2537\n",
      "Epoch 44/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.9979 - loss: 0.1328 - val_accuracy: 0.0516 - val_loss: 23.5245\n",
      "Epoch 45/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.9970 - loss: 0.1091 - val_accuracy: 0.0516 - val_loss: 23.7776\n",
      "Epoch 46/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - accuracy: 0.9958 - loss: 0.1051 - val_accuracy: 0.0452 - val_loss: 23.8907\n",
      "Epoch 47/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - accuracy: 0.9931 - loss: 0.0910 - val_accuracy: 0.0387 - val_loss: 24.1300\n",
      "Epoch 48/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9973 - loss: 0.0781 - val_accuracy: 0.0516 - val_loss: 24.3965\n",
      "Epoch 49/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 0.0590 - val_accuracy: 0.0452 - val_loss: 24.5450\n",
      "Epoch 50/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - accuracy: 0.9977 - loss: 0.0583 - val_accuracy: 0.0516 - val_loss: 24.7514\n",
      "Epoch 51/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.9989 - loss: 0.0521 - val_accuracy: 0.0452 - val_loss: 24.8471\n",
      "Epoch 52/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 0.0428 - val_accuracy: 0.0387 - val_loss: 25.0470\n",
      "Epoch 53/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 0.0405 - val_accuracy: 0.0452 - val_loss: 25.0887\n",
      "Epoch 54/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 1.0000 - loss: 0.0369 - val_accuracy: 0.0452 - val_loss: 25.1884\n",
      "Epoch 55/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 0.0348 - val_accuracy: 0.0516 - val_loss: 25.3489\n",
      "Epoch 56/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 0.0314 - val_accuracy: 0.0516 - val_loss: 25.4501\n",
      "Epoch 57/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 0.0284 - val_accuracy: 0.0387 - val_loss: 25.5711\n",
      "Epoch 58/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 0.0254 - val_accuracy: 0.0452 - val_loss: 25.6909\n",
      "Epoch 59/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 99ms/step - accuracy: 1.0000 - loss: 0.0242 - val_accuracy: 0.0452 - val_loss: 25.7628\n",
      "Epoch 60/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 0.0234 - val_accuracy: 0.0452 - val_loss: 25.8549\n",
      "Epoch 61/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 0.0213 - val_accuracy: 0.0452 - val_loss: 25.9483\n",
      "Epoch 62/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 0.0192 - val_accuracy: 0.0452 - val_loss: 26.0349\n",
      "Epoch 63/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 0.0195 - val_accuracy: 0.0387 - val_loss: 26.0837\n",
      "Epoch 64/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 0.0172 - val_accuracy: 0.0387 - val_loss: 26.2269\n",
      "Epoch 65/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 1.0000 - loss: 0.0170 - val_accuracy: 0.0387 - val_loss: 26.2282\n",
      "Epoch 66/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 0.0154 - val_accuracy: 0.0387 - val_loss: 26.3350\n",
      "Epoch 67/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 0.0143 - val_accuracy: 0.0452 - val_loss: 26.4255\n",
      "Epoch 68/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 0.0138 - val_accuracy: 0.0452 - val_loss: 26.5043\n",
      "Epoch 69/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 0.0133 - val_accuracy: 0.0387 - val_loss: 26.5468\n",
      "Epoch 70/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 0.0121 - val_accuracy: 0.0387 - val_loss: 26.6350\n",
      "Epoch 71/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 1.0000 - loss: 0.0115 - val_accuracy: 0.0387 - val_loss: 26.6726\n",
      "Epoch 72/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 1.0000 - loss: 0.0107 - val_accuracy: 0.0452 - val_loss: 26.7587\n",
      "Epoch 73/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 0.0103 - val_accuracy: 0.0387 - val_loss: 26.7914\n",
      "Epoch 74/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 0.0099 - val_accuracy: 0.0387 - val_loss: 26.8545\n",
      "Epoch 75/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 0.0095 - val_accuracy: 0.0387 - val_loss: 26.9324\n",
      "Epoch 76/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 1.0000 - loss: 0.0090 - val_accuracy: 0.0387 - val_loss: 26.9662\n",
      "Epoch 77/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 0.0088 - val_accuracy: 0.0387 - val_loss: 27.0620\n",
      "Epoch 78/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 0.0078 - val_accuracy: 0.0387 - val_loss: 27.0848\n",
      "Epoch 79/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 0.0074 - val_accuracy: 0.0452 - val_loss: 27.1438\n",
      "Epoch 80/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 0.0074 - val_accuracy: 0.0452 - val_loss: 27.1970\n",
      "Epoch 81/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 0.0452 - val_loss: 27.2551\n",
      "Epoch 82/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.0387 - val_loss: 27.2961\n",
      "Epoch 83/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 0.0452 - val_loss: 27.3680\n",
      "Epoch 84/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.0387 - val_loss: 27.4183\n",
      "Epoch 85/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 0.0057 - val_accuracy: 0.0387 - val_loss: 27.4714\n",
      "Epoch 86/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 0.0387 - val_loss: 27.5029\n",
      "Epoch 87/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.0387 - val_loss: 27.5609\n",
      "Epoch 88/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.0452 - val_loss: 27.6022\n",
      "Epoch 89/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.0452 - val_loss: 27.6534\n",
      "Epoch 90/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 0.0452 - val_loss: 27.6910\n",
      "Epoch 91/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.0452 - val_loss: 27.7291\n",
      "Epoch 92/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.0452 - val_loss: 27.7561\n",
      "Epoch 93/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.0452 - val_loss: 27.8115\n",
      "Epoch 94/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.0452 - val_loss: 27.8507\n",
      "Epoch 95/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.0452 - val_loss: 27.8865\n",
      "Epoch 96/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.0452 - val_loss: 27.9174\n",
      "Epoch 97/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.0452 - val_loss: 27.9747\n",
      "Epoch 98/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.0452 - val_loss: 28.0129\n",
      "Epoch 99/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.0452 - val_loss: 28.0568\n",
      "Epoch 100/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.0452 - val_loss: 28.1026\n",
      "\n",
      "Generated Text: The concept of AI  future introduction artificial intelligence ai is one to future introduction artificial the most revolutionary advancement of the 21st century it ha permeated every into three wave 1 symbolic ai 1950s1980s\n",
      "BLEU Score: 0.0000\n",
      "ROUGE Scores: {'rouge1': Score(precision=0.35714285714285715, recall=0.14705882352941177, fmeasure=0.20833333333333334), 'rouge2': Score(precision=0.23076923076923078, recall=0.09090909090909091, fmeasure=0.13043478260869568), 'rougeL': Score(precision=0.35714285714285715, recall=0.14705882352941177, fmeasure=0.20833333333333334)}\n",
      "Perplexity: 1602550059761.3469\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([clean_text])\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Convert text into sequences\n",
    "input_sequences = []\n",
    "words = clean_text.split()\n",
    "\n",
    "for i in range(1, len(words)):\n",
    "    sequence = words[:i+1]  # Create n-gram sequences\n",
    "    input_sequences.append(tokenizer.texts_to_sequences([' '.join(sequence)])[0])\n",
    "\n",
    "# Pad sequences\n",
    "max_seq_length = max([len(seq) for seq in input_sequences])\n",
    "input_sequences = pad_sequences(input_sequences, maxlen=max_seq_length, padding='pre')\n",
    "\n",
    "# Create input (X) and output (y)\n",
    "X, y = input_sequences[:, :-1], input_sequences[:, -1]\n",
    "y = to_categorical(y, num_classes=total_words)\n",
    "\n",
    "# Split into train (80%) and test (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Hyperparameter tuning function\n",
    "def build_model(hp):\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=total_words, output_dim=hp.Int('embedding_dim', min_value=50, max_value=200, step=50), input_length=max_seq_length-1),\n",
    "        LSTM(hp.Int('lstm_units', min_value=50, max_value=200, step=50), return_sequences=True),\n",
    "        Dropout(hp.Float('dropout', 0.1, 0.5, step=0.1)),\n",
    "        LSTM(hp.Int('lstm_units_2', min_value=50, max_value=200, step=50)),\n",
    "        Dense(hp.Int('dense_units', min_value=50, max_value=200, step=50), activation='relu'),\n",
    "        Dense(total_words, activation='softmax')\n",
    "    ])\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Hyperparameter tuning with Keras Tuner\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,  # Number of hyperparameter combinations\n",
    "    executions_per_trial=1,\n",
    "    directory='hyperparam_tuning',\n",
    "    project_name='text_gen_lstm'\n",
    ")\n",
    "\n",
    "# Run the tuner\n",
    "tuner.search(X_train, y_train, epochs=5, validation_data=(X_test, y_test))\n",
    "\n",
    "# Get the best model\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Train the best model\n",
    "model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "# Evaluation Metrics\n",
    "def calculate_perplexity(model, X, y):\n",
    "    loss, _ = model.evaluate(X, y, verbose=0)  # Categorical cross-entropy loss\n",
    "    return np.exp(loss)\n",
    "\n",
    "def generate_text(seed_text, next_words=10):\n",
    "    for _ in range(next_words):\n",
    "        tokenized_input = tokenizer.texts_to_sequences([seed_text])\n",
    "        padded_input = pad_sequences(tokenized_input, maxlen=max_seq_length-1, padding='pre')\n",
    "        predicted_word_index = np.argmax(model.predict(padded_input, verbose=0), axis=-1)[0]\n",
    "\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted_word_index:\n",
    "                seed_text += \" \" + word\n",
    "                break\n",
    "    return seed_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "ffHYqv3tHLNg",
    "outputId": "798f6eaa-b19e-411e-b222-9e4275a29612"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 02m 11s]\n",
      "val_accuracy: 0.05161290243268013\n",
      "\n",
      "Best val_accuracy So Far: 0.08387096971273422\n",
      "Total elapsed time: 00h 12m 45s\n",
      "Epoch 1/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - accuracy: 0.0048 - loss: 8.9676 - val_accuracy: 0.0000e+00 - val_loss: 8.8608\n",
      "Epoch 2/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.0209 - loss: 8.7422 - val_accuracy: 0.0000e+00 - val_loss: 8.7644\n",
      "Epoch 3/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.0258 - loss: 8.5820 - val_accuracy: 0.0000e+00 - val_loss: 8.6722\n",
      "Epoch 4/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 0.0357 - loss: 8.4331 - val_accuracy: 0.0000e+00 - val_loss: 8.5857\n",
      "Epoch 5/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.0488 - loss: 8.2755 - val_accuracy: 0.0000e+00 - val_loss: 8.5022\n",
      "Epoch 6/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.0603 - loss: 8.1180 - val_accuracy: 0.0000e+00 - val_loss: 8.4202\n",
      "Epoch 7/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.0709 - loss: 7.9671 - val_accuracy: 0.0000e+00 - val_loss: 8.3408\n",
      "Epoch 8/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.0654 - loss: 7.8346 - val_accuracy: 0.0000e+00 - val_loss: 8.2652\n",
      "Epoch 9/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.1045 - loss: 7.6368 - val_accuracy: 0.0000e+00 - val_loss: 8.1923\n",
      "Epoch 10/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.0996 - loss: 7.4890 - val_accuracy: 0.0000e+00 - val_loss: 8.1212\n",
      "Epoch 11/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.0834 - loss: 7.4038 - val_accuracy: 0.0000e+00 - val_loss: 8.0532\n",
      "Epoch 12/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.0862 - loss: 7.2609 - val_accuracy: 0.0000e+00 - val_loss: 7.9862\n",
      "Epoch 13/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.1309 - loss: 7.0741 - val_accuracy: 0.0129 - val_loss: 7.9227\n",
      "Epoch 14/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.0984 - loss: 6.9904 - val_accuracy: 0.0258 - val_loss: 7.8626\n",
      "Epoch 15/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.1045 - loss: 6.8583 - val_accuracy: 0.0194 - val_loss: 7.8050\n",
      "Epoch 16/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.1022 - loss: 6.6677 - val_accuracy: 0.0194 - val_loss: 7.7472\n",
      "Epoch 17/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.1238 - loss: 6.5583 - val_accuracy: 0.0258 - val_loss: 7.6899\n",
      "Epoch 18/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.0974 - loss: 6.4980 - val_accuracy: 0.0258 - val_loss: 7.6371\n",
      "Epoch 19/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.1135 - loss: 6.3785 - val_accuracy: 0.0323 - val_loss: 7.5857\n",
      "Epoch 20/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.1075 - loss: 6.2615 - val_accuracy: 0.0323 - val_loss: 7.5372\n",
      "Epoch 21/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.1032 - loss: 6.1367 - val_accuracy: 0.0323 - val_loss: 7.4945\n",
      "Epoch 22/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.1402 - loss: 5.9882 - val_accuracy: 0.0387 - val_loss: 7.4473\n",
      "Epoch 23/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.1165 - loss: 5.9519 - val_accuracy: 0.0323 - val_loss: 7.4053\n",
      "Epoch 24/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.1312 - loss: 5.8318 - val_accuracy: 0.0323 - val_loss: 7.3655\n",
      "Epoch 25/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.1045 - loss: 5.7561 - val_accuracy: 0.0323 - val_loss: 7.3240\n",
      "Epoch 26/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.1313 - loss: 5.6418 - val_accuracy: 0.0323 - val_loss: 7.2888\n",
      "Epoch 27/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.1288 - loss: 5.5829 - val_accuracy: 0.0323 - val_loss: 7.2594\n",
      "Epoch 28/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.1183 - loss: 5.4764 - val_accuracy: 0.0323 - val_loss: 7.2319\n",
      "Epoch 29/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.1305 - loss: 5.3761 - val_accuracy: 0.0258 - val_loss: 7.2087\n",
      "Epoch 30/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 0.1295 - loss: 5.2916 - val_accuracy: 0.0258 - val_loss: 7.1941\n",
      "Epoch 31/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.1233 - loss: 5.2625 - val_accuracy: 0.0323 - val_loss: 7.1800\n",
      "Epoch 32/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.1380 - loss: 5.1562 - val_accuracy: 0.0387 - val_loss: 7.1773\n",
      "Epoch 33/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.1331 - loss: 5.1041 - val_accuracy: 0.0387 - val_loss: 7.1692\n",
      "Epoch 34/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.1442 - loss: 5.0009 - val_accuracy: 0.0323 - val_loss: 7.1873\n",
      "Epoch 35/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.1608 - loss: 4.8800 - val_accuracy: 0.0516 - val_loss: 7.1873\n",
      "Epoch 36/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.1556 - loss: 4.8233 - val_accuracy: 0.0516 - val_loss: 7.2194\n",
      "Epoch 37/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.1640 - loss: 4.7436 - val_accuracy: 0.0452 - val_loss: 7.2361\n",
      "Epoch 38/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.1543 - loss: 4.7089 - val_accuracy: 0.0516 - val_loss: 7.2561\n",
      "Epoch 39/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 0.1678 - loss: 4.6272 - val_accuracy: 0.0516 - val_loss: 7.2706\n",
      "Epoch 40/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.1846 - loss: 4.5189 - val_accuracy: 0.0516 - val_loss: 7.3123\n",
      "Epoch 41/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.1634 - loss: 4.5432 - val_accuracy: 0.0516 - val_loss: 7.3390\n",
      "Epoch 42/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.1919 - loss: 4.4089 - val_accuracy: 0.0516 - val_loss: 7.3518\n",
      "Epoch 43/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.1842 - loss: 4.3738 - val_accuracy: 0.0581 - val_loss: 7.3858\n",
      "Epoch 44/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.1986 - loss: 4.3133 - val_accuracy: 0.0516 - val_loss: 7.4551\n",
      "Epoch 45/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.1886 - loss: 4.2477 - val_accuracy: 0.0516 - val_loss: 7.4923\n",
      "Epoch 46/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.2127 - loss: 4.1741 - val_accuracy: 0.0452 - val_loss: 7.5476\n",
      "Epoch 47/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.2292 - loss: 4.1224 - val_accuracy: 0.0516 - val_loss: 7.5726\n",
      "Epoch 48/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.1916 - loss: 4.1060 - val_accuracy: 0.0516 - val_loss: 7.6182\n",
      "Epoch 49/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.2461 - loss: 3.9148 - val_accuracy: 0.0452 - val_loss: 7.6590\n",
      "Epoch 50/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.2171 - loss: 4.0162 - val_accuracy: 0.0516 - val_loss: 7.6938\n",
      "Epoch 51/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.2258 - loss: 3.9224 - val_accuracy: 0.0581 - val_loss: 7.7300\n",
      "Epoch 52/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.2208 - loss: 3.8961 - val_accuracy: 0.0516 - val_loss: 7.7088\n",
      "Epoch 53/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.2460 - loss: 3.7820 - val_accuracy: 0.0516 - val_loss: 7.8536\n",
      "Epoch 54/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.2513 - loss: 3.7497 - val_accuracy: 0.0516 - val_loss: 7.8198\n",
      "Epoch 55/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.2912 - loss: 3.7037 - val_accuracy: 0.0516 - val_loss: 7.8967\n",
      "Epoch 56/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.2758 - loss: 3.6396 - val_accuracy: 0.0516 - val_loss: 7.9406\n",
      "Epoch 57/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.2845 - loss: 3.5754 - val_accuracy: 0.0581 - val_loss: 7.9655\n",
      "Epoch 58/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.2992 - loss: 3.5474 - val_accuracy: 0.0581 - val_loss: 7.9923\n",
      "Epoch 59/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.3083 - loss: 3.4638 - val_accuracy: 0.0516 - val_loss: 8.0660\n",
      "Epoch 60/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.3039 - loss: 3.4491 - val_accuracy: 0.0581 - val_loss: 8.1097\n",
      "Epoch 61/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.3123 - loss: 3.4004 - val_accuracy: 0.0645 - val_loss: 8.1657\n",
      "Epoch 62/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.3411 - loss: 3.2772 - val_accuracy: 0.0581 - val_loss: 8.2300\n",
      "Epoch 63/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.3390 - loss: 3.2922 - val_accuracy: 0.0516 - val_loss: 8.3064\n",
      "Epoch 64/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.3195 - loss: 3.2762 - val_accuracy: 0.0581 - val_loss: 8.2899\n",
      "Epoch 65/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.3522 - loss: 3.1915 - val_accuracy: 0.0645 - val_loss: 8.4813\n",
      "Epoch 66/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.3500 - loss: 3.1745 - val_accuracy: 0.0516 - val_loss: 8.4822\n",
      "Epoch 67/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.3839 - loss: 3.0375 - val_accuracy: 0.0581 - val_loss: 8.5468\n",
      "Epoch 68/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.4008 - loss: 3.0045 - val_accuracy: 0.0645 - val_loss: 8.8434\n",
      "Epoch 69/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.4136 - loss: 2.9575 - val_accuracy: 0.0645 - val_loss: 8.6343\n",
      "Epoch 70/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.4463 - loss: 2.9186 - val_accuracy: 0.0516 - val_loss: 8.6901\n",
      "Epoch 71/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.4041 - loss: 2.9194 - val_accuracy: 0.0710 - val_loss: 8.6977\n",
      "Epoch 72/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.4381 - loss: 2.8845 - val_accuracy: 0.0645 - val_loss: 8.9901\n",
      "Epoch 73/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.4220 - loss: 2.8479 - val_accuracy: 0.0645 - val_loss: 8.7776\n",
      "Epoch 74/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.4064 - loss: 2.7823 - val_accuracy: 0.0645 - val_loss: 8.8407\n",
      "Epoch 75/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.4526 - loss: 2.7737 - val_accuracy: 0.0581 - val_loss: 8.8095\n",
      "Epoch 76/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.4610 - loss: 2.7239 - val_accuracy: 0.0581 - val_loss: 9.1177\n",
      "Epoch 77/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.4486 - loss: 2.7126 - val_accuracy: 0.0645 - val_loss: 9.0297\n",
      "Epoch 78/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.4863 - loss: 2.6141 - val_accuracy: 0.0581 - val_loss: 9.2343\n",
      "Epoch 79/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.4684 - loss: 2.6487 - val_accuracy: 0.0710 - val_loss: 9.0155\n",
      "Epoch 80/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.5360 - loss: 2.4804 - val_accuracy: 0.0710 - val_loss: 9.1242\n",
      "Epoch 81/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.5049 - loss: 2.5274 - val_accuracy: 0.0645 - val_loss: 9.1985\n",
      "Epoch 82/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.5682 - loss: 2.4011 - val_accuracy: 0.0645 - val_loss: 9.0939\n",
      "Epoch 83/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.5386 - loss: 2.4416 - val_accuracy: 0.0645 - val_loss: 9.1537\n",
      "Epoch 84/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.5511 - loss: 2.3763 - val_accuracy: 0.0645 - val_loss: 9.1526\n",
      "Epoch 85/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6048 - loss: 2.3472 - val_accuracy: 0.0645 - val_loss: 8.6739\n",
      "Epoch 86/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.5539 - loss: 2.3411 - val_accuracy: 0.0516 - val_loss: 8.8758\n",
      "Epoch 87/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.5925 - loss: 2.3022 - val_accuracy: 0.0581 - val_loss: 9.0952\n",
      "Epoch 88/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.6011 - loss: 2.2675 - val_accuracy: 0.0581 - val_loss: 9.0606\n",
      "Epoch 89/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.5895 - loss: 2.2353 - val_accuracy: 0.0645 - val_loss: 9.4321\n",
      "Epoch 90/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.6130 - loss: 2.2069 - val_accuracy: 0.0645 - val_loss: 9.2737\n",
      "Epoch 91/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.5872 - loss: 2.1589 - val_accuracy: 0.0645 - val_loss: 9.0563\n",
      "Epoch 92/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6673 - loss: 2.1116 - val_accuracy: 0.0645 - val_loss: 9.1953\n",
      "Epoch 93/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.6393 - loss: 2.0764 - val_accuracy: 0.0516 - val_loss: 8.9116\n",
      "Epoch 94/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6494 - loss: 2.0827 - val_accuracy: 0.0452 - val_loss: 8.6777\n",
      "Epoch 95/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6955 - loss: 2.0080 - val_accuracy: 0.0516 - val_loss: 8.8576\n",
      "Epoch 96/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7061 - loss: 1.9949 - val_accuracy: 0.0645 - val_loss: 9.4132\n",
      "Epoch 97/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.6920 - loss: 1.9892 - val_accuracy: 0.0581 - val_loss: 9.4510\n",
      "Epoch 98/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.6999 - loss: 1.9263 - val_accuracy: 0.0581 - val_loss: 9.3796\n",
      "Epoch 99/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7025 - loss: 1.9617 - val_accuracy: 0.0581 - val_loss: 9.3188\n",
      "Epoch 100/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7045 - loss: 1.9267 - val_accuracy: 0.0774 - val_loss: 9.5996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x793da4b9c110>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Early Stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Model with Regularization, Dropout, and Early Stopping\n",
    "def build_model(hp):\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=total_words, output_dim=hp.Int('embedding_dim', min_value=50, max_value=200, step=50), input_length=max_seq_length-1),\n",
    "        LSTM(hp.Int('lstm_units', min_value=50, max_value=100, step=50), return_sequences=True, kernel_regularizer=l2(0.01)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(hp.Float('dropout', 0.1, 0.5, step=0.1)),\n",
    "        LSTM(hp.Int('lstm_units_2', min_value=50, max_value=100, step=50), kernel_regularizer=l2(0.01)),\n",
    "        BatchNormalization(),\n",
    "        Dense(hp.Int('dense_units', min_value=50, max_value=100, step=50), activation='relu'),\n",
    "        Dense(total_words, activation='softmax')\n",
    "    ])\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.0001), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Hyperparameter tuning\n",
    "tuner_new = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=1,\n",
    "    directory='hyperparam_tuning1',\n",
    "    project_name='text_gen_lstm1'\n",
    ")\n",
    "\n",
    "# Run the tuner\n",
    "tuner_new.search(X_train, y_train, epochs=100, validation_data=(X_test, y_test))\n",
    "\n",
    "# Get best model and train\n",
    "best_hps = tuner_new.get_best_hyperparameters(num_trials=5)[0]\n",
    "model = tuner_new.hypermodel.build(best_hps)\n",
    "model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "iOieRrSuM57F",
    "outputId": "13a0b3f5-0dba-46d0-b4f8-9548c4a0a4a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 41s]\n",
      "val_accuracy: 0.03870967775583267\n",
      "\n",
      "Best val_accuracy So Far: 0.06451612710952759\n",
      "Total elapsed time: 00h 02m 54s\n",
      "Epoch 1/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - accuracy: 0.0052 - loss: 8.7204 - val_accuracy: 0.0387 - val_loss: 8.0966\n",
      "Epoch 2/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.0403 - loss: 7.7695 - val_accuracy: 0.0452 - val_loss: 7.5115\n",
      "Epoch 3/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.0633 - loss: 6.9532 - val_accuracy: 0.0452 - val_loss: 7.1264\n",
      "Epoch 4/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.0971 - loss: 6.2769 - val_accuracy: 0.0452 - val_loss: 6.8911\n",
      "Epoch 5/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.0943 - loss: 5.7828 - val_accuracy: 0.0452 - val_loss: 6.7387\n",
      "Epoch 6/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.0770 - loss: 5.3173 - val_accuracy: 0.0452 - val_loss: 6.6379\n",
      "Epoch 7/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.1248 - loss: 4.9117 - val_accuracy: 0.0387 - val_loss: 6.5653\n",
      "Epoch 8/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.1137 - loss: 4.7098 - val_accuracy: 0.0129 - val_loss: 6.5135\n",
      "Epoch 9/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.1391 - loss: 4.3232 - val_accuracy: 0.0129 - val_loss: 6.4772\n",
      "Epoch 10/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.1620 - loss: 3.9976 - val_accuracy: 0.0323 - val_loss: 6.4627\n",
      "Epoch 11/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.2118 - loss: 3.6586 - val_accuracy: 0.0323 - val_loss: 6.4473\n",
      "Epoch 12/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.2334 - loss: 3.4418 - val_accuracy: 0.0258 - val_loss: 6.4319\n",
      "Epoch 13/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.2864 - loss: 3.1631 - val_accuracy: 0.0258 - val_loss: 6.4289\n",
      "Epoch 14/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.3405 - loss: 2.8999 - val_accuracy: 0.0065 - val_loss: 6.4055\n",
      "Epoch 15/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.3421 - loss: 2.7268 - val_accuracy: 0.0323 - val_loss: 6.4002\n",
      "Epoch 16/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.3685 - loss: 2.5011 - val_accuracy: 0.0129 - val_loss: 6.4125\n",
      "Epoch 17/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.4053 - loss: 2.3084 - val_accuracy: 0.0194 - val_loss: 6.4252\n",
      "Epoch 18/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.4563 - loss: 2.1152 - val_accuracy: 0.0129 - val_loss: 6.4881\n",
      "Epoch 19/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.5026 - loss: 1.9779 - val_accuracy: 0.0258 - val_loss: 6.5546\n",
      "Epoch 20/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.5310 - loss: 1.8171 - val_accuracy: 0.0129 - val_loss: 6.5934\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x793d2c4c4110>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras_tuner as kt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dropout, Dense, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Early stopping to avoid overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Function to build the model\n",
    "def build_model(hp):\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=total_words,\n",
    "                  output_dim=hp.Int('embedding_dim', min_value=50, max_value=200, step=50),\n",
    "                  input_length=max_seq_length-1),\n",
    "        LSTM(hp.Int('lstm_units', min_value=50, max_value=100, step=50),\n",
    "             return_sequences=True, kernel_regularizer=l2(0.01)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(hp.Float('dropout', 0.1, 0.5, step=0.1)),\n",
    "        LSTM(hp.Int('lstm_units_2', min_value=50, max_value=100, step=50),\n",
    "             kernel_regularizer=l2(0.01)),\n",
    "        BatchNormalization(),\n",
    "        Dense(hp.Int('dense_units', min_value=50, max_value=100, step=50), activation='relu'),\n",
    "        Dense(total_words, activation='softmax')\n",
    "    ])\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Use Bayesian Optimization instead of Random Search\n",
    "tuner = kt.BayesianOptimization(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,  # Number of hyperparameter combinations to try\n",
    "    executions_per_trial=1,\n",
    "    directory='hyperparam_tuning5',\n",
    "    project_name='text_gen_lstm_bayesian'\n",
    ")\n",
    "\n",
    "# Perform hyperparameter tuning\n",
    "tuner.search(X_train, y_train, epochs=30, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Build and train the best model\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test), callbacks=[early_stopping], verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "lT3gsfuHH1BH",
    "outputId": "a0ff72cb-32a9-4a6e-b048-be313606002e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Text: Artificial Intelligence intelligence transforming transforming intelligence future future intelligence intelligence future future artificial is is is is is ai the and a ai a in a a in a a ai a\n",
      "BLEU Score: 0.0000\n",
      "ROUGE Scores: {'rouge1': Score(precision=0.35714285714285715, recall=0.15625, fmeasure=0.21739130434782608), 'rouge2': Score(precision=0.07692307692307693, recall=0.03225806451612903, fmeasure=0.045454545454545456), 'rougeL': Score(precision=0.2857142857142857, recall=0.125, fmeasure=0.17391304347826086)}\n",
      "Perplexity: 601.9516\n"
     ]
    }
   ],
   "source": [
    "# Example evaluation\n",
    "generated_text = generate_text(\"Artificial Intelligence\", next_words=30)\n",
    "\n",
    "# Assuming reference_text is a list of lists\n",
    "reference_text = [[\"Artificial Intelligence (AI) is one of the most revolutionary advancements of the 21st century\"]]\n",
    "candidate_text = generated_text.split()\n",
    "\n",
    "# Compute BLEU Score\n",
    "smooth_fn = SmoothingFunction().method1  # Apply smoothing\n",
    "bleu_score = sentence_bleu(reference_text, candidate_text, smoothing_function=smooth_fn)\n",
    "\n",
    "# Compute ROUGE Score\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "rouge_scores = scorer.score(\" \".join(candidate_text), \" \".join(reference_text[0]))\n",
    "\n",
    "# Compute Perplexity\n",
    "perplexity = calculate_perplexity(model, X_test, y_test)\n",
    "\n",
    "# Print results\n",
    "print(f\"\\nGenerated Text: {generated_text}\")\n",
    "print(f\"BLEU Score: {bleu_score:.4f}\")\n",
    "print(f\"ROUGE Scores: {rouge_scores}\")\n",
    "print(f\"Perplexity: {perplexity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Au8cEVvJEFs2",
    "outputId": "4c065a6e-6795-4b87-eaf8-1a93d94fff56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Text: Artificial  intelligence transforming transforming transforming transforming transforming transforming transforming transforming transforming transforming transforming transforming transforming transforming transforming transforming transforming transforming transforming transforming transforming transforming transforming transforming transforming transforming transforming transforming transforming\n",
      "BLEU Score: 0.0000\n",
      "ROUGE Scores: {'rouge1': Score(precision=0.16666666666666666, recall=0.06451612903225806, fmeasure=0.09302325581395349), 'rouge2': Score(precision=0.09090909090909091, recall=0.03333333333333333, fmeasure=0.04878048780487805), 'rougeL': Score(precision=0.16666666666666666, recall=0.06451612903225806, fmeasure=0.09302325581395349)}\n",
      "Perplexity: 293737530932.1476\n"
     ]
    }
   ],
   "source": [
    "# Evaluation Metrics\n",
    "def calculate_perplexity(model, X, y):\n",
    "    loss, _ = model.evaluate(X, y, verbose=0)  # Categorical cross-entropy loss\n",
    "    return np.exp(loss)\n",
    "\n",
    "def generate_text(seed_text, next_words=10):\n",
    "    for _ in range(next_words):\n",
    "        tokenized_input = tokenizer.texts_to_sequences([seed_text])\n",
    "        padded_input = pad_sequences(tokenized_input, maxlen=max_seq_length-1, padding='pre')\n",
    "        predicted_word_index = np.argmax(model.predict(padded_input, verbose=0), axis=-1)[0]\n",
    "\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted_word_index:\n",
    "                seed_text += \" \" + word\n",
    "                break\n",
    "    return seed_text\n",
    "\n",
    "# Example evaluation\n",
    "generated_text = generate_text(\"Artificial \", next_words=30)\n",
    "\n",
    "# Assuming reference_text is a list of lists\n",
    "reference_text = [[\"Artificial Intelligence (AI) is one of the most revolutionary advancements in technology.\"]]\n",
    "candidate_text = generated_text.split()\n",
    "\n",
    "# Compute BLEU Score\n",
    "smooth_fn = SmoothingFunction().method1  # Apply smoothing\n",
    "bleu_score = sentence_bleu(reference_text, candidate_text, smoothing_function=smooth_fn)\n",
    "\n",
    "# Compute ROUGE Score\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "rouge_scores = scorer.score(\" \".join(candidate_text), \" \".join(reference_text[0]))\n",
    "\n",
    "# Compute Perplexity\n",
    "perplexity = calculate_perplexity(model, X_test, y_test)\n",
    "\n",
    "# Print results\n",
    "print(f\"\\nGenerated Text: {generated_text}\")\n",
    "print(f\"BLEU Score: {bleu_score:.4f}\")\n",
    "print(f\"ROUGE Scores: {rouge_scores}\")\n",
    "print(f\"Perplexity: {perplexity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PQh_x6s0utY5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "cognizant_projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
